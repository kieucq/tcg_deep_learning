{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "311c26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing, svm, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebe18bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lat    lon  MaxWind  RMW  MIN_SLP  SHR_MAG  SHR_HDG  STM_SPD  STM_HDG  \\\n",
      "0  11.4  306.5       45   60     1006        5      324       12      275   \n",
      "1  11.6  305.3       44   72     1003        5      350       15      270   \n",
      "2  11.8  304.2       50   62     1002        4      323       13      279   \n",
      "3  12.1  302.9       52  139     1002        4      268       11      290   \n",
      "4  12.5  301.7       50   25     1002        6      243        9      283   \n",
      "5  13.3  299.8       42   57     1006        3        8       13      293   \n",
      "6  15.0  298.1       45   76     1005        3      320       14      296   \n",
      "7  15.8  297.3       38   36     1005        7        2       13      288   \n",
      "8  16.4  296.6       50  154     1004        7       31       12      310   \n",
      "9  17.1  296.0       52   90     1002        6       76       14      314   \n",
      "\n",
      "   SST  TPW  LAND  850TANG  850VORT  200DVRG  class  \n",
      "0  278   47   636       72       28      -18      0  \n",
      "1  280   47   617       71        9      -13      0  \n",
      "2  280   46   558       76        5       15      0  \n",
      "3  282   47   449       82       14        5      0  \n",
      "4  282   48   349       90       12       10      0  \n",
      "5  284   48   291       79        5       28      0  \n",
      "6  286   49   476       81        0       -1      0  \n",
      "7  287   49   419       60        7       10      0  \n",
      "8  286   48   319       66       -8       26      0  \n",
      "9  286   49   224       75        0       16      0  \n",
      "[  11.4  306.5   45.    60.  1006.     5.   324.    12.   275.   278.\n",
      "   47.   636.    72.    28.   -18. ]\n",
      "0\n",
      "data length is 388\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# reading all input data, and replace/remove bad data. Note that this data set \n",
    "# must contain the last column \"class\" that indicates RI (1) or non-RI (0).\n",
    "#\n",
    "flag_input_more_time=\"yes\"\n",
    "if flag_input_more_time == \"yes\":\n",
    "    df = pd.read_csv('AllBasinsMaster(+12).csv')\n",
    "    df.drop(['OHC','OHC(+6h)','OHC(+12h)'], axis=1, inplace=True)\n",
    "else:\n",
    "    df = pd.read_csv('AtlanticMajorHurricane2016-2019.csv')\n",
    "    df.drop(['OHC'], axis=1, inplace=True)\n",
    "#df.replace(9999,-1111, inplace=True)\n",
    "#df.replace('?',-99999, inplace=True)    \n",
    "print(df.head(10))\n",
    "x = np.array(df.drop(['class'],axis=1))\n",
    "y = np.array(df['class'])\n",
    "print(x[0])\n",
    "print(y[0])\n",
    "print(\"data length is\" ,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0907a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 1675 292.0 287.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# splitting total dataframe into RI and non-RI data for later dealing with unbalanced\n",
    "# data set.\n",
    "#\n",
    "df_ri = []\n",
    "df_nonri = []\n",
    "for i in range(len(df)):\n",
    "    if df['class'][i] == 1:\n",
    "        df_ri.append(df.loc[i,:])\n",
    "    else:\n",
    "        df_nonri.append(df.loc[i,:])  \n",
    "print(len(df_ri),len(df_nonri), df_ri[50]['SST'],df_nonri[50]['SST(+12h)'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb379acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# create a function that randomly selects from non-RI data (df_nonri) a net set \n",
    "# with the same length as RI data (df_ri). The training and prediction will be carried out only \n",
    "# for the combined set (update_x_data) to maintain the balanced data between RI and non-RI.\n",
    "# No need to create y data, as the df data contains the label in the last column.\n",
    "#\n",
    "import random\n",
    "def generate_data(df_ri,df_nonri):    \n",
    "    my_list = list(range(1,len(df_nonri)))                               \n",
    "    random.shuffle(my_list)\n",
    "    new_x_data = []\n",
    "    new_y_data = []\n",
    "    #\n",
    "    # randomize the nonRI data first\n",
    "    #\n",
    "    for i in my_list[:len(df_ri)]:\n",
    "        new_x_data.append(df_nonri[i])\n",
    "        #new_y_data.append(df_nonri[i]['class'])\n",
    "    #\n",
    "    # join nonRI and RI data into a single list\n",
    "    #\n",
    "    for j in df_ri:\n",
    "        new_x_data.append(j)    \n",
    "        #new_y_data.append(t['class'])        \n",
    "    #\n",
    "    # randomize the final list\n",
    "    #\n",
    "    new_list = list(range(len(new_x_data)))\n",
    "    random.shuffle(new_list)\n",
    "    #print(new_list)\n",
    "    update_x_data = []\n",
    "    #update_y_data = []\n",
    "    for i in new_list:\n",
    "        update_x_data.append(new_x_data[i])        \n",
    "        #update_y_data.append(new_y_data[i])        \n",
    "    return update_x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5c4af00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data length is:  16\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# reading a new SHIP record to make a prediction\n",
    "#\n",
    "if flag_input_more_time == \"yes\":\n",
    "    df = pd.read_csv('ship_input_12h.csv')\n",
    "    df.drop(['OHC','OHC(+6h)','OHC(+12h)'], axis=1, inplace=True)\n",
    "else:\n",
    "    df = pd.read_csv('ship_input.csv')\n",
    "    df.drop(['OHC'], axis=1, inplace=True)\n",
    "df.replace('?',-99999, inplace=True)\n",
    "x_fcst = np.array(df.drop(['class'],axis=1))\n",
    "y_fcst = np.array(df['class'])\n",
    "print('Test data length is: ',len(x_fcst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "731b38f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for realization  0  is 0.6363636363636364\n",
      "The accuracy for realization  1  is 0.6818181818181818\n",
      "The accuracy for realization  2  is 0.8181818181818182\n",
      "The accuracy for realization  3  is 0.6818181818181818\n",
      "The accuracy for realization  4  is 0.7727272727272727\n",
      "The accuracy for realization  5  is 0.7272727272727273\n",
      "The accuracy for realization  6  is 0.5454545454545454\n",
      "The accuracy for realization  7  is 0.7272727272727273\n",
      "The accuracy for realization  8  is 0.5\n",
      "The accuracy for realization  9  is 0.6818181818181818\n",
      "The accuracy for realization  10  is 0.7272727272727273\n",
      "The accuracy for realization  11  is 0.7727272727272727\n",
      "The accuracy for realization  12  is 0.6818181818181818\n",
      "The accuracy for realization  13  is 0.6363636363636364\n",
      "The accuracy for realization  14  is 0.6818181818181818\n",
      "The accuracy for realization  15  is 0.6818181818181818\n",
      "The accuracy for realization  16  is 0.6363636363636364\n",
      "The accuracy for realization  17  is 0.6363636363636364\n",
      "The accuracy for realization  18  is 0.5\n",
      "The accuracy for realization  19  is 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# training for each realization and make a forecast for each realization. \n",
    "#\n",
    "num_realizations = 20\n",
    "forecast = np.zeros((len(x_fcst),num_realizations))\n",
    "for realization in range(num_realizations):\n",
    "    z = np.array(generate_data(df_ri,df_nonri))    \n",
    "    n_sample = len(z)\n",
    "    n_predictors = len(z[0])-1\n",
    "    x_new = np.zeros((n_sample,n_predictors))\n",
    "    y_new = np.zeros(n_sample)\n",
    "    x_new[:,:n_predictors] = z[:,:n_predictors]\n",
    "    y_new[:] = z[:,n_predictors]\n",
    "    #print(len(z),len(z[0]),z[0,15],z[50,15],z[54,15],z[101,15])\n",
    "    #print(y_new[0],y_new[50],y_new[54],y_new[101])\n",
    "    #print(x_new[10],y_new[10])\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size=0.1)\n",
    "    clf = neighbors.KNeighborsClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    accuracy = clf.score(x_test, y_test)\n",
    "    pred = clf.predict(x_test)\n",
    "    print(\"The accuracy for realization \",realization,\" is\", accuracy)\n",
    "    #print(classification_report(y_test,pred,zero_division=1))    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_test,pred))\n",
    "    \n",
    "    single_fcst = clf.predict(x_fcst)\n",
    "    forecast[:,realization] = single_fcst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86a26830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual RI 0  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Predicted RI Propbability:  0.05\n",
      "Actual RI 0  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Predicted RI Propbability:  0.05\n",
      "Actual RI 0  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]  Predicted RI Propbability:  0.2\n",
      "Actual RI 0  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Predicted RI Propbability:  0.0\n",
      "Actual RI 0  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Predicted RI Propbability:  0.0\n",
      "Actual RI 1  <--->  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  Predicted RI Propbability:  1.0\n",
      "Actual RI 1  <--->  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]  Predicted RI Propbability:  0.95\n",
      "Actual RI 1  <--->  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  Predicted RI Propbability:  1.0\n",
      "Actual RI 1  <--->  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  Predicted RI Propbability:  1.0\n",
      "Actual RI 0  <--->  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]  Predicted RI Propbability:  1.0\n",
      "Actual RI 0  <--->  [0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]  Predicted RI Propbability:  0.5\n",
      "Actual RI 0  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Predicted RI Propbability:  0.05\n",
      "Actual RI 1  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]  Predicted RI Propbability:  0.05\n",
      "Actual RI 1  <--->  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Predicted RI Propbability:  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(forecast)):\n",
    "    print(\"Actual RI\",y_fcst[i],\" <---> \",forecast[i,:],\" Predicted RI Propbability: \",sum(forecast[i,:])/num_realizations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
