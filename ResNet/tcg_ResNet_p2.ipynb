{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b4ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NOTE: This ResNet model is for predicting TC formation, using the \n",
    "#       architechture provided in deep-learning coursera. The model treats \n",
    "#       different 2D input fields as input channels of an image. This specific\n",
    "#       program requires a set of input data from Stage 2 of the following\n",
    "#       3-stage workflow\n",
    "#       - Stage 1: reading NETCDF input and generating (X,y) data with a\n",
    "#                  given image sizes, which are then saved by pickle;\n",
    "#       - Stage 2: import the saved pickle (X,y) pair and build a CNN model\n",
    "#                  with a given training/validation ratio, and then save\n",
    "#                  the train model under tcg_CNN.model.\n",
    "#       - Stage 3: import the trained model from Stage 2, and make a list\n",
    "#                  of prediction from normalized test data.\n",
    "#\n",
    "# INPUT: This Stage 2 script requires two specific input datasets that are\n",
    "#        generated from Step 1, including\n",
    "#        1. tcg_ResNet_X.pickle: data contains all images of yes/no TCG events, \n",
    "#           each of these images must have 12 channels\n",
    "#        2. tcg_ResNet_y.pickle: data contains all labels of each image (i.e., \n",
    "#           yes or no) of TCG corresponding to each data in X.\n",
    "#\n",
    "#        Remarks: Note that each channel must be normalized separately. Also,\n",
    "#        the script requires a large memory allocation. So users need to have\n",
    "#        GPU version to run this.\n",
    "#\n",
    "# OUTPUT: The best ResNet model built from Keras that is saved under \n",
    "#        tcg_ResNet.model\n",
    "#\n",
    "# HIST: - 27, May 23: Created by CK from the open source ResNet50 model in \n",
    "#                     the deep learning course.\n",
    "#       - 12, Jun 23: Added ResNet-20, and ResNet-22 model and re-organized the\n",
    "#                     workflow for better fit with the TCG prediction problem.\n",
    "#       - 18, Nov 23: re-designed the workflow for better maintenance in the \n",
    "#                     future. Also the histories are saved in pickle for Stage 3\n",
    "#                     to make it easier to check.\n",
    "#\n",
    "# AUTH: Chanh Kieu (Indiana University, Bloomington. Email: ckieu@iu.edu)\n",
    "#===============================================================================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "import pickle\n",
    "import sys\n",
    "import libtcg_utils as tcg_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98d533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Building the identity_block for ResNet with 3 convolutional layers\n",
    "#\n",
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):        \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. Will need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of the main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path    \n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    \n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X) \n",
    "    return X\n",
    "# \n",
    "# Building the convolutional_block for ResNet with 3 convolutional layers\n",
    "#\n",
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X) \n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    \n",
    "    # Shortcut path \n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "# \n",
    "# Building the ResNet-40 model for TCG classifications. The default input shape is a \n",
    "# tuple (30,30,12), but the actual shape is passed from the function call below. \n",
    "# Likewise, the default number of classes is 1.\n",
    "#\n",
    "def ResNet40(input_shape = (30, 30, 12), classes = 1):\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((2, 2))(X_input)\n",
    "    \n",
    "    # Stage 1 - 1 layer\n",
    "    X = Conv2D(64, (5, 5), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 1)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2 - 9 layers\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    # Stage 3 - 12 layers\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "   \n",
    "    # the 3 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4 - 18 layers    \n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    \n",
    "    # the 5 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5 - 9 layers    \n",
    "    #X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    \n",
    "    # the 2 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    #X = identity_block(X, 3, [512, 512, 2048])\n",
    "    #X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D()(X)\"\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    # output layer - 1 dense layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', kernel_initializer = glorot_uniform(seed=0))(X)    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model\n",
    "#\n",
    "# ResNet-22 model\n",
    "#\n",
    "def ResNet22(input_shape = (30, 30, 12), classes = 1):\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((2, 2))(X_input)\n",
    "\n",
    "    # Stage 1 - 1 layer\n",
    "    X = Conv2D(64, (5, 5), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 1)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2 - 9 layers\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    # Stage 3 - 12 layers\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "\n",
    "    # the 3 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D()(X)\"\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    # output layer - 1 dense layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model\n",
    "#\n",
    "# ResNet-20 model\n",
    "#\n",
    "def ResNet20(input_shape = (30, 30, 12), classes = 1):\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((2, 2))(X_input)\n",
    "\n",
    "    # Stage 1 - 1 layer\n",
    "    X = Conv2D(64, (5, 5), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 1)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2 - 9 layers\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    # Stage 3 - 9 layers\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])    \n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D()(X)\"\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    # output layer - 1 dense layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f5badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# call ResNet model and printout the summary. Note that the number of parameters for the\n",
    "# batch normalization is computed as 4x # of filter due to the use of 4 parameters:\n",
    "# [gamma weights, beta weights, moving_mean(non-trainable), moving_variance(non-trainable)]\n",
    "# for each filter normalization.\n",
    "#\n",
    "def main(resnet_models=['ResNet20'],X=[],y=[],lead_time='00'):\n",
    "    histories = []\n",
    "    for resnet in resnet_models:\n",
    "        NAME = \"model_{}_{}h\".format(resnet,lead_time)\n",
    "        print('--> Running configuration: ',NAME)\n",
    "        if resnet == \"ResNet20\":\n",
    "            model = ResNet20(input_shape = (X.shape[1], X.shape[2], X.shape[3]), classes = 1)\n",
    "        elif resnet == \"ResNet22\":\n",
    "            model = ResNet22(input_shape = (X.shape[1], X.shape[2], X.shape[3]), classes = 1)\n",
    "        elif resnet == \"ResNet40\":\n",
    "            model = ResNet40(input_shape = (X.shape[1], X.shape[2], X.shape[3]), classes = 1)\n",
    "        model.summary()\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.3)])\n",
    "        callbacks=[keras.callbacks.ModelCheckpoint(\"tcg_\" + resnet + \".model_\" + str(lead_time),save_best_only=True)]\n",
    "        hist = model.fit(X, Y, epochs = 100, batch_size = 128, validation_split=0.1, callbacks=callbacks)\n",
    "        histories.append(hist.history)\n",
    "    return histories\n",
    "#\n",
    "# Visualize the output of the training model (work for jupyter notebook only)\n",
    "#\n",
    "def view_history(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    val_accuracy = history.history['val_binary_accuracy']\n",
    "    accuracy = history.history['binary_accuracy']\n",
    "    epochs = history.epoch\n",
    "    plt.plot(epochs,val_accuracy,'r',label=\"val binary_accuracy\")\n",
    "    plt.plot(epochs,accuracy,'b',label=\"train binary_accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    val_loss = history.history['val_loss']\n",
    "    loss = history.history['loss']\n",
    "    plt.plot(epochs,val_loss,'r',label=\"val loss\")\n",
    "    plt.plot(epochs,loss,'b',label=\"train loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d9b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total arguments input are: 3\n",
      "Name of Python script: /N/u/ckieu/Carbonate/.local/lib/python3.10/site-packages/ipykernel_launcher.py\n",
      "Forecast lead time to run is:  -f\n",
      "Input shape of the X features data:  (708, 32, 32, 12)\n",
      "Input shape of the y label data:  (708,)\n",
      "Number of input channel extracted from X is:  12\n",
      "Finish normalization...\n",
      "number of input examples = 708\n",
      "X shape: (708, 32, 32, 12)\n",
      "Y shape: (708,)\n",
      "--> Running configuration:  model_ResNet20_-fh\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 32, 32, 12)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadding2  (None, 36, 36, 12)  0           ['input_4[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 16, 16, 64)   19264       ['zero_padding2d_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 16, 16, 64)  64          ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)    0           ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 7, 7, 64)     4160        ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 7, 7, 64)    256         ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 7, 7, 64)     36928       ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 7, 7, 64)    256         ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 7, 7, 256)    16640       ['activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 7, 7, 256)    16640       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 7, 7, 256)   1024        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 7, 7, 256)   1024        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 7, 7, 256)    0           ['batch_normalization_91[0][0]', \n",
      "                                                                  'batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 7, 7, 256)    0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 7, 7, 64)     16448       ['activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 7, 7, 64)    256         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 7, 7, 64)     36928       ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 7, 7, 64)    256         ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 7, 7, 256)    16640       ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 7, 7, 256)   1024        ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 7, 7, 256)    0           ['activation_84[0][0]',          \n",
      "                                                                  'batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 7, 7, 256)    0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 7, 7, 64)     16448       ['activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 7, 7, 64)    256         ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 7, 7, 64)     36928       ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 7, 7, 64)    256         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 7, 7, 256)    16640       ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 7, 7, 256)   1024        ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 7, 7, 256)    0           ['activation_87[0][0]',          \n",
      "                                                                  'batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 7, 7, 256)    0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 4, 4, 128)    32896       ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 4, 4, 128)   512         ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 4, 4, 128)   512         ['conv2d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 4, 4, 512)    131584      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 4, 4, 512)   2048        ['conv2d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 4, 4, 512)   2048        ['conv2d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 4, 4, 512)    0           ['batch_normalization_101[0][0]',\n",
      "                                                                  'batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 4, 4, 512)    0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 4, 4, 128)   512         ['conv2d_103[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 4, 4, 128)   512         ['conv2d_104[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 4, 4, 512)   2048        ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 4, 4, 512)    0           ['activation_93[0][0]',          \n",
      "                                                                  'batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 4, 4, 512)    0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 4, 4, 128)   512         ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 4, 4, 128)   512         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 4, 4, 512)   2048        ['conv2d_108[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 4, 4, 512)    0           ['activation_96[0][0]',          \n",
      "                                                                  'batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 4, 4, 512)    0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 2, 2, 512)   0           ['activation_99[0][0]']          \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 2048)         0           ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            2049        ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,189,377\n",
      "Trainable params: 1,180,897\n",
      "Non-trainable params: 8,480\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.6652 - binary_accuracy: 0.7637 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet20.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet20.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 19s 2s/step - loss: 0.6039 - binary_accuracy: 0.7881 - val_loss: 0.3913 - val_binary_accuracy: 0.9014\n",
      "Epoch 2/100\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.1236 - binary_accuracy: 0.9629"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet20.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet20.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 7s 2s/step - loss: 0.1094 - binary_accuracy: 0.9686 - val_loss: 0.1277 - val_binary_accuracy: 0.9014\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1285 - binary_accuracy: 0.9498 - val_loss: 0.1894 - val_binary_accuracy: 0.9437\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0419 - binary_accuracy: 0.9812 - val_loss: 0.2398 - val_binary_accuracy: 0.9296\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0208 - binary_accuracy: 0.9937 - val_loss: 0.2292 - val_binary_accuracy: 0.9296\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0091 - binary_accuracy: 0.9969 - val_loss: 0.1682 - val_binary_accuracy: 0.9859\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4794e-04 - binary_accuracy: 1.0000 - val_loss: 0.1983 - val_binary_accuracy: 0.9718\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 0.2004 - val_binary_accuracy: 0.9718\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.6365e-04 - binary_accuracy: 1.0000 - val_loss: 0.1902 - val_binary_accuracy: 0.9718\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.4398e-04 - binary_accuracy: 1.0000 - val_loss: 0.1838 - val_binary_accuracy: 0.9718\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.2170e-04 - binary_accuracy: 1.0000 - val_loss: 0.1855 - val_binary_accuracy: 0.9718\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.2068e-04 - binary_accuracy: 1.0000 - val_loss: 0.1913 - val_binary_accuracy: 0.9718\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.1100e-04 - binary_accuracy: 1.0000 - val_loss: 0.1976 - val_binary_accuracy: 0.9718\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.4623e-05 - binary_accuracy: 1.0000 - val_loss: 0.2032 - val_binary_accuracy: 0.9718\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.9042e-05 - binary_accuracy: 1.0000 - val_loss: 0.2078 - val_binary_accuracy: 0.9718\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.0423e-05 - binary_accuracy: 1.0000 - val_loss: 0.2117 - val_binary_accuracy: 0.9718\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4188e-05 - binary_accuracy: 1.0000 - val_loss: 0.2141 - val_binary_accuracy: 0.9718\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2073e-05 - binary_accuracy: 1.0000 - val_loss: 0.2159 - val_binary_accuracy: 0.9718\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.6558e-05 - binary_accuracy: 1.0000 - val_loss: 0.2180 - val_binary_accuracy: 0.9718\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3551e-05 - binary_accuracy: 1.0000 - val_loss: 0.2194 - val_binary_accuracy: 0.9718\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.7028e-05 - binary_accuracy: 1.0000 - val_loss: 0.2210 - val_binary_accuracy: 0.9718\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.8227e-05 - binary_accuracy: 1.0000 - val_loss: 0.2229 - val_binary_accuracy: 0.9718\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6857e-05 - binary_accuracy: 1.0000 - val_loss: 0.2247 - val_binary_accuracy: 0.9718\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.0287e-05 - binary_accuracy: 1.0000 - val_loss: 0.2263 - val_binary_accuracy: 0.9718\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.0217e-05 - binary_accuracy: 1.0000 - val_loss: 0.2275 - val_binary_accuracy: 0.9718\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.5298e-05 - binary_accuracy: 1.0000 - val_loss: 0.2293 - val_binary_accuracy: 0.9718\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.8687e-05 - binary_accuracy: 1.0000 - val_loss: 0.2313 - val_binary_accuracy: 0.9718\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.3123e-05 - binary_accuracy: 1.0000 - val_loss: 0.2331 - val_binary_accuracy: 0.9718\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.3822e-05 - binary_accuracy: 1.0000 - val_loss: 0.2347 - val_binary_accuracy: 0.9718\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.4883e-05 - binary_accuracy: 1.0000 - val_loss: 0.2360 - val_binary_accuracy: 0.9718\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.8441e-05 - binary_accuracy: 1.0000 - val_loss: 0.2373 - val_binary_accuracy: 0.9718\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.3352e-05 - binary_accuracy: 1.0000 - val_loss: 0.2386 - val_binary_accuracy: 0.9718\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5274e-05 - binary_accuracy: 1.0000 - val_loss: 0.2397 - val_binary_accuracy: 0.9718\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.1890e-05 - binary_accuracy: 1.0000 - val_loss: 0.2406 - val_binary_accuracy: 0.9718\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.4237e-05 - binary_accuracy: 1.0000 - val_loss: 0.2414 - val_binary_accuracy: 0.9718\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4310e-05 - binary_accuracy: 1.0000 - val_loss: 0.2433 - val_binary_accuracy: 0.9718\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.0955e-05 - binary_accuracy: 1.0000 - val_loss: 0.2450 - val_binary_accuracy: 0.9718\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.0654e-05 - binary_accuracy: 1.0000 - val_loss: 0.2461 - val_binary_accuracy: 0.9718\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.3677e-05 - binary_accuracy: 1.0000 - val_loss: 0.2467 - val_binary_accuracy: 0.9718\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.2887e-05 - binary_accuracy: 1.0000 - val_loss: 0.2473 - val_binary_accuracy: 0.9718\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.2400e-05 - binary_accuracy: 1.0000 - val_loss: 0.2478 - val_binary_accuracy: 0.9718\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6293e-06 - binary_accuracy: 1.0000 - val_loss: 0.2483 - val_binary_accuracy: 0.9718\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.1074e-05 - binary_accuracy: 1.0000 - val_loss: 0.2489 - val_binary_accuracy: 0.9718\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7210e-06 - binary_accuracy: 1.0000 - val_loss: 0.2493 - val_binary_accuracy: 0.9718\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.1574e-05 - binary_accuracy: 1.0000 - val_loss: 0.2497 - val_binary_accuracy: 0.9718\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.0839e-05 - binary_accuracy: 1.0000 - val_loss: 0.2505 - val_binary_accuracy: 0.9718\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.9512e-06 - binary_accuracy: 1.0000 - val_loss: 0.2511 - val_binary_accuracy: 0.9718\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.2566e-06 - binary_accuracy: 1.0000 - val_loss: 0.2516 - val_binary_accuracy: 0.9718\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.3847e-05 - binary_accuracy: 1.0000 - val_loss: 0.2519 - val_binary_accuracy: 0.9718\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.4951e-06 - binary_accuracy: 1.0000 - val_loss: 0.2523 - val_binary_accuracy: 0.9718\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.3860e-05 - binary_accuracy: 1.0000 - val_loss: 0.2527 - val_binary_accuracy: 0.9718\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1084e-06 - binary_accuracy: 1.0000 - val_loss: 0.2533 - val_binary_accuracy: 0.9718\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8916e-06 - binary_accuracy: 1.0000 - val_loss: 0.2538 - val_binary_accuracy: 0.9718\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8843e-06 - binary_accuracy: 1.0000 - val_loss: 0.2544 - val_binary_accuracy: 0.9718\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8017e-06 - binary_accuracy: 1.0000 - val_loss: 0.2548 - val_binary_accuracy: 0.9718\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.9806e-05 - binary_accuracy: 1.0000 - val_loss: 0.2542 - val_binary_accuracy: 0.9718\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5580e-06 - binary_accuracy: 1.0000 - val_loss: 0.2521 - val_binary_accuracy: 0.9718\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8203e-06 - binary_accuracy: 1.0000 - val_loss: 0.2509 - val_binary_accuracy: 0.9718\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3959e-06 - binary_accuracy: 1.0000 - val_loss: 0.2503 - val_binary_accuracy: 0.9718\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3197e-06 - binary_accuracy: 1.0000 - val_loss: 0.2502 - val_binary_accuracy: 0.9718\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1715e-06 - binary_accuracy: 1.0000 - val_loss: 0.2502 - val_binary_accuracy: 0.9718\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.2496e-06 - binary_accuracy: 1.0000 - val_loss: 0.2504 - val_binary_accuracy: 0.9718\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.9619e-06 - binary_accuracy: 1.0000 - val_loss: 0.2507 - val_binary_accuracy: 0.9718\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.5494e-06 - binary_accuracy: 1.0000 - val_loss: 0.2510 - val_binary_accuracy: 0.9718\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4347e-06 - binary_accuracy: 1.0000 - val_loss: 0.2514 - val_binary_accuracy: 0.9718\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.9522e-06 - binary_accuracy: 1.0000 - val_loss: 0.2519 - val_binary_accuracy: 0.9718\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.8083e-06 - binary_accuracy: 1.0000 - val_loss: 0.2526 - val_binary_accuracy: 0.9718\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9682e-06 - binary_accuracy: 1.0000 - val_loss: 0.2533 - val_binary_accuracy: 0.9718\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.6185e-06 - binary_accuracy: 1.0000 - val_loss: 0.2539 - val_binary_accuracy: 0.9718\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6252e-06 - binary_accuracy: 1.0000 - val_loss: 0.2544 - val_binary_accuracy: 0.9718\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9923e-06 - binary_accuracy: 1.0000 - val_loss: 0.2549 - val_binary_accuracy: 0.9718\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.0948e-06 - binary_accuracy: 1.0000 - val_loss: 0.2552 - val_binary_accuracy: 0.9718\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9199e-06 - binary_accuracy: 1.0000 - val_loss: 0.2556 - val_binary_accuracy: 0.9718\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.5782e-06 - binary_accuracy: 1.0000 - val_loss: 0.2559 - val_binary_accuracy: 0.9718\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.7477e-06 - binary_accuracy: 1.0000 - val_loss: 0.2562 - val_binary_accuracy: 0.9718\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.7611e-06 - binary_accuracy: 1.0000 - val_loss: 0.2564 - val_binary_accuracy: 0.9718\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4578e-06 - binary_accuracy: 1.0000 - val_loss: 0.2566 - val_binary_accuracy: 0.9718\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.5343e-06 - binary_accuracy: 1.0000 - val_loss: 0.2569 - val_binary_accuracy: 0.9718\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.7553e-06 - binary_accuracy: 1.0000 - val_loss: 0.2572 - val_binary_accuracy: 0.9718\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8413e-06 - binary_accuracy: 1.0000 - val_loss: 0.2574 - val_binary_accuracy: 0.9718\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.5772e-06 - binary_accuracy: 1.0000 - val_loss: 0.2577 - val_binary_accuracy: 0.9718\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.2231e-06 - binary_accuracy: 1.0000 - val_loss: 0.2580 - val_binary_accuracy: 0.9718\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.4281e-06 - binary_accuracy: 1.0000 - val_loss: 0.2582 - val_binary_accuracy: 0.9718\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4107e-06 - binary_accuracy: 1.0000 - val_loss: 0.2586 - val_binary_accuracy: 0.9718\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1632e-06 - binary_accuracy: 1.0000 - val_loss: 0.2594 - val_binary_accuracy: 0.9718\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6774e-06 - binary_accuracy: 1.0000 - val_loss: 0.2600 - val_binary_accuracy: 0.9718\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9606e-06 - binary_accuracy: 1.0000 - val_loss: 0.2604 - val_binary_accuracy: 0.9718\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.8266e-06 - binary_accuracy: 1.0000 - val_loss: 0.2608 - val_binary_accuracy: 0.9718\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.9790e-06 - binary_accuracy: 1.0000 - val_loss: 0.2611 - val_binary_accuracy: 0.9718\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.3119e-06 - binary_accuracy: 1.0000 - val_loss: 0.2614 - val_binary_accuracy: 0.9718\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.0884e-06 - binary_accuracy: 1.0000 - val_loss: 0.2616 - val_binary_accuracy: 0.9718\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4210e-06 - binary_accuracy: 1.0000 - val_loss: 0.2619 - val_binary_accuracy: 0.9718\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.6559e-06 - binary_accuracy: 1.0000 - val_loss: 0.2622 - val_binary_accuracy: 0.9718\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.0263e-06 - binary_accuracy: 1.0000 - val_loss: 0.2625 - val_binary_accuracy: 0.9718\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.5248e-06 - binary_accuracy: 1.0000 - val_loss: 0.2628 - val_binary_accuracy: 0.9718\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.1059e-06 - binary_accuracy: 1.0000 - val_loss: 0.2631 - val_binary_accuracy: 0.9718\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.1054e-05 - binary_accuracy: 1.0000 - val_loss: 0.2634 - val_binary_accuracy: 0.9718\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.6853e-06 - binary_accuracy: 1.0000 - val_loss: 0.2641 - val_binary_accuracy: 0.9718\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2.5759e-06 - binary_accuracy: 1.0000 - val_loss: 0.2645 - val_binary_accuracy: 0.9718\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.9434e-06 - binary_accuracy: 1.0000 - val_loss: 0.2648 - val_binary_accuracy: 0.9718\n",
      "--> Running configuration:  model_ResNet22_-fh\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 32, 32, 12)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 36, 36, 12)  0           ['input_5[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 16, 16, 64)   19264       ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 16, 16, 64)  64          ['conv2d_109[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 64)    0           ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 7, 7, 64)     4160        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 7, 7, 64)    256         ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 7, 7, 64)    256         ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 7, 7, 256)    16640       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 7, 7, 256)    16640       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 7, 7, 256)   1024        ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 7, 7, 256)   1024        ['conv2d_113[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 7, 7, 256)    0           ['batch_normalization_112[0][0]',\n",
      "                                                                  'batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 7, 7, 256)    0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 7, 7, 64)     16448       ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 7, 7, 64)    256         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_104[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 7, 7, 64)    256         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 7, 7, 256)    16640       ['activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 7, 7, 256)   1024        ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 7, 7, 256)    0           ['activation_103[0][0]',         \n",
      "                                                                  'batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 7, 7, 256)    0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 7, 7, 64)     16448       ['activation_106[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 7, 7, 64)    256         ['conv2d_117[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 7, 7, 64)    256         ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 7, 7, 256)    16640       ['activation_108[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 7, 7, 256)   1024        ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 7, 7, 256)    0           ['activation_106[0][0]',         \n",
      "                                                                  'batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 7, 7, 256)    0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 4, 4, 128)    32896       ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 4, 4, 128)   512         ['conv2d_120[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 4, 4, 128)   512         ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_111[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 4, 4, 512)    131584      ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 4, 4, 512)   2048        ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 4, 4, 512)   2048        ['conv2d_123[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 4, 4, 512)    0           ['batch_normalization_122[0][0]',\n",
      "                                                                  'batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 4, 4, 512)    0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 4, 4, 128)   512         ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_113[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 4, 4, 128)   512         ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 4, 4, 512)   2048        ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 4, 4, 512)    0           ['activation_112[0][0]',         \n",
      "                                                                  'batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 4, 4, 512)    0           ['add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_115[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 4, 4, 128)   512         ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 4, 4, 128)   512         ['conv2d_128[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 4, 4, 512)   2048        ['conv2d_129[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 4, 4, 512)    0           ['activation_115[0][0]',         \n",
      "                                                                  'batch_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 4, 4, 512)    0           ['add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_118[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 4, 4, 128)   512         ['conv2d_130[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 4, 4, 128)   512         ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_120[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 4, 4, 512)   2048        ['conv2d_132[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 4, 4, 512)    0           ['activation_118[0][0]',         \n",
      "                                                                  'batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 4, 4, 512)    0           ['add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 2, 2, 512)   0           ['activation_121[0][0]']         \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 2048)         0           ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            2049        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,471,745\n",
      "Trainable params: 1,461,729\n",
      "Non-trainable params: 10,016\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.1877 - binary_accuracy: 0.7227 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet22.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet22.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 22s 2s/step - loss: 1.0140 - binary_accuracy: 0.7661 - val_loss: 0.2919 - val_binary_accuracy: 0.9155\n",
      "Epoch 2/100\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.2641 - binary_accuracy: 0.9043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet22.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet22.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 8s 2s/step - loss: 0.2609 - binary_accuracy: 0.9027 - val_loss: 0.1314 - val_binary_accuracy: 0.9577\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0844 - binary_accuracy: 0.9608 - val_loss: 0.1686 - val_binary_accuracy: 0.9718\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0519 - binary_accuracy: 0.9890 - val_loss: 0.1533 - val_binary_accuracy: 0.9718\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0410 - binary_accuracy: 0.9780 - val_loss: 0.1813 - val_binary_accuracy: 0.9718\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0070 - binary_accuracy: 0.9953 - val_loss: 0.1789 - val_binary_accuracy: 0.9577\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0130 - binary_accuracy: 0.9984 - val_loss: 0.1807 - val_binary_accuracy: 0.9718\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.7829e-04 - binary_accuracy: 1.0000 - val_loss: 0.1915 - val_binary_accuracy: 0.9859\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0050 - binary_accuracy: 0.9984 - val_loss: 0.2243 - val_binary_accuracy: 0.9718\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0425e-04 - binary_accuracy: 1.0000 - val_loss: 0.2043 - val_binary_accuracy: 0.9859\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5910e-04 - binary_accuracy: 1.0000 - val_loss: 0.1968 - val_binary_accuracy: 0.9859\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.8054e-04 - binary_accuracy: 1.0000 - val_loss: 0.1898 - val_binary_accuracy: 0.9859\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.1421e-04 - binary_accuracy: 1.0000 - val_loss: 0.1884 - val_binary_accuracy: 0.9859\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.7253e-05 - binary_accuracy: 1.0000 - val_loss: 0.1882 - val_binary_accuracy: 0.9859\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.2605e-04 - binary_accuracy: 1.0000 - val_loss: 0.1894 - val_binary_accuracy: 0.9859\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.2852e-04 - binary_accuracy: 1.0000 - val_loss: 0.1926 - val_binary_accuracy: 0.9859\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.4165e-05 - binary_accuracy: 1.0000 - val_loss: 0.1949 - val_binary_accuracy: 0.9859\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.4859e-05 - binary_accuracy: 1.0000 - val_loss: 0.1969 - val_binary_accuracy: 0.9859\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.3556e-05 - binary_accuracy: 1.0000 - val_loss: 0.1983 - val_binary_accuracy: 0.9859\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.0920e-05 - binary_accuracy: 1.0000 - val_loss: 0.1989 - val_binary_accuracy: 0.9859\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.9121e-05 - binary_accuracy: 1.0000 - val_loss: 0.1993 - val_binary_accuracy: 0.9859\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5369e-05 - binary_accuracy: 1.0000 - val_loss: 0.1996 - val_binary_accuracy: 0.9859\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.4072e-05 - binary_accuracy: 1.0000 - val_loss: 0.1999 - val_binary_accuracy: 0.9859\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.8063e-05 - binary_accuracy: 1.0000 - val_loss: 0.2002 - val_binary_accuracy: 0.9859\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.6355e-05 - binary_accuracy: 1.0000 - val_loss: 0.2003 - val_binary_accuracy: 0.9859\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5428e-05 - binary_accuracy: 1.0000 - val_loss: 0.2006 - val_binary_accuracy: 0.9859\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.4255e-05 - binary_accuracy: 1.0000 - val_loss: 0.2008 - val_binary_accuracy: 0.9859\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.1000e-05 - binary_accuracy: 1.0000 - val_loss: 0.2010 - val_binary_accuracy: 0.9859\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.7946e-05 - binary_accuracy: 1.0000 - val_loss: 0.2012 - val_binary_accuracy: 0.9859\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.1692e-05 - binary_accuracy: 1.0000 - val_loss: 0.2014 - val_binary_accuracy: 0.9859\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.6277e-05 - binary_accuracy: 1.0000 - val_loss: 0.2015 - val_binary_accuracy: 0.9859\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.3415e-05 - binary_accuracy: 1.0000 - val_loss: 0.2018 - val_binary_accuracy: 0.9859\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.2430e-05 - binary_accuracy: 1.0000 - val_loss: 0.2023 - val_binary_accuracy: 0.9859\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.1120e-05 - binary_accuracy: 1.0000 - val_loss: 0.2026 - val_binary_accuracy: 0.9859\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.2251e-05 - binary_accuracy: 1.0000 - val_loss: 0.2028 - val_binary_accuracy: 0.9859\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6899e-06 - binary_accuracy: 1.0000 - val_loss: 0.2031 - val_binary_accuracy: 0.9859\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.4058e-05 - binary_accuracy: 1.0000 - val_loss: 0.2034 - val_binary_accuracy: 0.9859\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.2601e-05 - binary_accuracy: 1.0000 - val_loss: 0.2039 - val_binary_accuracy: 0.9859\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6308e-06 - binary_accuracy: 1.0000 - val_loss: 0.2044 - val_binary_accuracy: 0.9859\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3485e-06 - binary_accuracy: 1.0000 - val_loss: 0.2048 - val_binary_accuracy: 0.9859\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.2807e-05 - binary_accuracy: 1.0000 - val_loss: 0.2050 - val_binary_accuracy: 0.9859\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6190e-06 - binary_accuracy: 1.0000 - val_loss: 0.2052 - val_binary_accuracy: 0.9859\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.1639e-06 - binary_accuracy: 1.0000 - val_loss: 0.2053 - val_binary_accuracy: 0.9859\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.1821e-05 - binary_accuracy: 1.0000 - val_loss: 0.2054 - val_binary_accuracy: 0.9859\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.9355e-05 - binary_accuracy: 1.0000 - val_loss: 0.2061 - val_binary_accuracy: 0.9859\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8547e-06 - binary_accuracy: 1.0000 - val_loss: 0.2069 - val_binary_accuracy: 0.9859\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.0645e-06 - binary_accuracy: 1.0000 - val_loss: 0.2075 - val_binary_accuracy: 0.9859\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.8376e-06 - binary_accuracy: 1.0000 - val_loss: 0.2080 - val_binary_accuracy: 0.9859\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.4107e-05 - binary_accuracy: 1.0000 - val_loss: 0.2083 - val_binary_accuracy: 0.9859\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.2420e-06 - binary_accuracy: 1.0000 - val_loss: 0.2088 - val_binary_accuracy: 0.9859\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.0325e-05 - binary_accuracy: 1.0000 - val_loss: 0.2092 - val_binary_accuracy: 0.9859\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6466e-06 - binary_accuracy: 1.0000 - val_loss: 0.2089 - val_binary_accuracy: 0.9859\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.7080e-06 - binary_accuracy: 1.0000 - val_loss: 0.2088 - val_binary_accuracy: 0.9859\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3779e-06 - binary_accuracy: 1.0000 - val_loss: 0.2088 - val_binary_accuracy: 0.9859\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.0539e-06 - binary_accuracy: 1.0000 - val_loss: 0.2089 - val_binary_accuracy: 0.9859\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.6633e-06 - binary_accuracy: 1.0000 - val_loss: 0.2090 - val_binary_accuracy: 0.9859\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.5454e-06 - binary_accuracy: 1.0000 - val_loss: 0.2092 - val_binary_accuracy: 0.9859\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.5070e-06 - binary_accuracy: 1.0000 - val_loss: 0.2094 - val_binary_accuracy: 0.9859\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.5868e-06 - binary_accuracy: 1.0000 - val_loss: 0.2094 - val_binary_accuracy: 0.9859\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3943e-06 - binary_accuracy: 1.0000 - val_loss: 0.2095 - val_binary_accuracy: 0.9859\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.1204e-06 - binary_accuracy: 1.0000 - val_loss: 0.2097 - val_binary_accuracy: 0.9859\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.8748e-06 - binary_accuracy: 1.0000 - val_loss: 0.2098 - val_binary_accuracy: 0.9859\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2261e-06 - binary_accuracy: 1.0000 - val_loss: 0.2100 - val_binary_accuracy: 0.9859\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.2307e-06 - binary_accuracy: 1.0000 - val_loss: 0.2102 - val_binary_accuracy: 0.9859\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.2924e-06 - binary_accuracy: 1.0000 - val_loss: 0.2104 - val_binary_accuracy: 0.9859\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.3557e-06 - binary_accuracy: 1.0000 - val_loss: 0.2104 - val_binary_accuracy: 0.9859\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.0273e-06 - binary_accuracy: 1.0000 - val_loss: 0.2105 - val_binary_accuracy: 0.9859\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.7983e-06 - binary_accuracy: 1.0000 - val_loss: 0.2106 - val_binary_accuracy: 0.9859\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.4293e-06 - binary_accuracy: 1.0000 - val_loss: 0.2108 - val_binary_accuracy: 0.9859\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.2359e-06 - binary_accuracy: 1.0000 - val_loss: 0.2109 - val_binary_accuracy: 0.9859\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.4854e-06 - binary_accuracy: 1.0000 - val_loss: 0.2110 - val_binary_accuracy: 0.9859\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3911e-06 - binary_accuracy: 1.0000 - val_loss: 0.2111 - val_binary_accuracy: 0.9859\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.8513e-06 - binary_accuracy: 1.0000 - val_loss: 0.2112 - val_binary_accuracy: 0.9859\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.3969e-06 - binary_accuracy: 1.0000 - val_loss: 0.2114 - val_binary_accuracy: 0.9859\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.2762e-06 - binary_accuracy: 1.0000 - val_loss: 0.2115 - val_binary_accuracy: 0.9859\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.9556e-06 - binary_accuracy: 1.0000 - val_loss: 0.2115 - val_binary_accuracy: 0.9859\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.1249e-06 - binary_accuracy: 1.0000 - val_loss: 0.2117 - val_binary_accuracy: 0.9859\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.2908e-06 - binary_accuracy: 1.0000 - val_loss: 0.2117 - val_binary_accuracy: 0.9859\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.5762e-06 - binary_accuracy: 1.0000 - val_loss: 0.2118 - val_binary_accuracy: 0.9859\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.0025e-06 - binary_accuracy: 1.0000 - val_loss: 0.2119 - val_binary_accuracy: 0.9859\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7136e-06 - binary_accuracy: 1.0000 - val_loss: 0.2120 - val_binary_accuracy: 0.9859\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2.9098e-06 - binary_accuracy: 1.0000 - val_loss: 0.2120 - val_binary_accuracy: 0.9859\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.8743e-06 - binary_accuracy: 1.0000 - val_loss: 0.2120 - val_binary_accuracy: 0.9859\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.1099e-06 - binary_accuracy: 1.0000 - val_loss: 0.2117 - val_binary_accuracy: 0.9859\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.7757e-06 - binary_accuracy: 1.0000 - val_loss: 0.2115 - val_binary_accuracy: 0.9859\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.3824e-06 - binary_accuracy: 1.0000 - val_loss: 0.2115 - val_binary_accuracy: 0.9859\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.9383e-06 - binary_accuracy: 1.0000 - val_loss: 0.2114 - val_binary_accuracy: 0.9859\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.2116e-05 - binary_accuracy: 1.0000 - val_loss: 0.2119 - val_binary_accuracy: 0.9859\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.4626e-06 - binary_accuracy: 1.0000 - val_loss: 0.2123 - val_binary_accuracy: 0.9859\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.2928e-06 - binary_accuracy: 1.0000 - val_loss: 0.2126 - val_binary_accuracy: 0.9859\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.7077e-06 - binary_accuracy: 1.0000 - val_loss: 0.2129 - val_binary_accuracy: 0.9859\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.3585e-06 - binary_accuracy: 1.0000 - val_loss: 0.2131 - val_binary_accuracy: 0.9859\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.0921e-06 - binary_accuracy: 1.0000 - val_loss: 0.2132 - val_binary_accuracy: 0.9859\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.4571e-06 - binary_accuracy: 1.0000 - val_loss: 0.2134 - val_binary_accuracy: 0.9859\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.5439e-06 - binary_accuracy: 1.0000 - val_loss: 0.2136 - val_binary_accuracy: 0.9859\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.4543e-06 - binary_accuracy: 1.0000 - val_loss: 0.2141 - val_binary_accuracy: 0.9859\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.9183e-06 - binary_accuracy: 1.0000 - val_loss: 0.2143 - val_binary_accuracy: 0.9859\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.3653e-06 - binary_accuracy: 1.0000 - val_loss: 0.2145 - val_binary_accuracy: 0.9859\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.7070e-06 - binary_accuracy: 1.0000 - val_loss: 0.2147 - val_binary_accuracy: 0.9859\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.9233e-06 - binary_accuracy: 1.0000 - val_loss: 0.2148 - val_binary_accuracy: 0.9859\n",
      "--> Running configuration:  model_ResNet40_-fh\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 32, 32, 12)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 36, 36, 12)  0           ['input_6[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 16, 16, 64)   19264       ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 16, 16, 64)  64          ['conv2d_133[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 64)    0           ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 7, 7, 64)     4160        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 7, 7, 64)    256         ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_123[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 7, 7, 64)    256         ['conv2d_135[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 7, 7, 256)    16640       ['activation_124[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 7, 7, 256)    16640       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 7, 7, 256)   1024        ['conv2d_136[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 7, 7, 256)   1024        ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 7, 7, 256)    0           ['batch_normalization_136[0][0]',\n",
      "                                                                  'batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 7, 7, 256)    0           ['add_39[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 7, 7, 64)     16448       ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 7, 7, 64)    256         ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 7, 7, 64)    256         ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 7, 7, 256)    16640       ['activation_127[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 7, 7, 256)   1024        ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 7, 7, 256)    0           ['activation_125[0][0]',         \n",
      "                                                                  'batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 7, 7, 256)    0           ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 7, 7, 64)     16448       ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 7, 7, 64)    256         ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 7, 7, 64)    256         ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 7, 7, 256)    16640       ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 7, 7, 256)   1024        ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 7, 7, 256)    0           ['activation_128[0][0]',         \n",
      "                                                                  'batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 7, 7, 256)    0           ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 4, 4, 128)    32896       ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 4, 4, 128)   512         ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_132[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 4, 4, 128)   512         ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 4, 4, 512)    131584      ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 4, 4, 512)   2048        ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 4, 4, 512)   2048        ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 4, 4, 512)    0           ['batch_normalization_146[0][0]',\n",
      "                                                                  'batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 4, 4, 512)    0           ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_134[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 4, 4, 128)   512         ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 4, 4, 128)   512         ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 4, 4, 512)   2048        ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 4, 4, 512)    0           ['activation_134[0][0]',         \n",
      "                                                                  'batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 4, 4, 512)    0           ['add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_137[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 4, 4, 128)   512         ['conv2d_151[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 4, 4, 128)   512         ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 4, 4, 512)   2048        ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 4, 4, 512)    0           ['activation_137[0][0]',         \n",
      "                                                                  'batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 4, 4, 512)    0           ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 4, 4, 128)    65664       ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 4, 4, 128)   512         ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 4, 4, 128)    147584      ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 4, 4, 128)   512         ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 4, 4, 512)    66048       ['activation_142[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 4, 4, 512)   2048        ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 4, 4, 512)    0           ['activation_140[0][0]',         \n",
      "                                                                  'batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 4, 4, 512)    0           ['add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 2, 2, 256)    131328      ['activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 2, 2, 256)   1024        ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_144[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 2, 2, 256)   1024        ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 2, 2, 1024)   525312      ['activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_159[0][0]',\n",
      "                                                                  'batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 2, 2, 1024)   0           ['add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 2, 2, 256)   1024        ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_147[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 2, 2, 256)   1024        ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_163[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 2, 2, 1024)   0           ['activation_146[0][0]',         \n",
      "                                                                  'batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 2, 2, 1024)   0           ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 2, 2, 256)   1024        ['conv2d_164[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 2, 2, 256)   1024        ['conv2d_165[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_151[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_166[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 2, 2, 1024)   0           ['activation_149[0][0]',         \n",
      "                                                                  'batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 2, 2, 1024)   0           ['add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_152[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 2, 2, 256)   1024        ['conv2d_167[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 2, 2, 256)   1024        ['conv2d_168[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_154[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_169[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 2, 2, 1024)   0           ['activation_152[0][0]',         \n",
      "                                                                  'batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 2, 2, 1024)   0           ['add_49[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 2, 2, 256)   1024        ['conv2d_170[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 2, 2, 256)   1024        ['conv2d_171[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_157[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_172[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 2, 2, 1024)   0           ['activation_155[0][0]',         \n",
      "                                                                  'batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 2, 2, 1024)   0           ['add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 2, 2, 256)   1024        ['conv2d_173[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 2, 2, 256)   1024        ['conv2d_174[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_175[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 2, 2, 1024)   0           ['activation_158[0][0]',         \n",
      "                                                                  'batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 2, 2, 1024)   0           ['add_51[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 1, 1, 1024)  0           ['activation_161[0][0]']         \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 1024)         0           ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            1025        ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,599,809\n",
      "Trainable params: 8,569,313\n",
      "Non-trainable params: 30,496\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9865 - binary_accuracy: 0.7441 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 43). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 38s 4s/step - loss: 0.9865 - binary_accuracy: 0.7441 - val_loss: 0.2235 - val_binary_accuracy: 0.9014\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3071 - binary_accuracy: 0.8854 - val_loss: 0.3437 - val_binary_accuracy: 0.9155\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.1632 - binary_accuracy: 0.9372 - val_loss: 0.6098 - val_binary_accuracy: 0.8169\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.1362 - binary_accuracy: 0.9372 - val_loss: 0.3388 - val_binary_accuracy: 0.9296\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0430 - binary_accuracy: 0.9874 - val_loss: 0.3829 - val_binary_accuracy: 0.9155\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0301 - binary_accuracy: 0.9874 - val_loss: 0.3474 - val_binary_accuracy: 0.9155\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0050 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 43). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 15s 4s/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.2171 - val_binary_accuracy: 0.9437\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0013 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 43). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 14s 4s/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 0.1716 - val_binary_accuracy: 0.9577\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 5.7048e-04 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 43). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 14s 4s/step - loss: 5.7048e-04 - binary_accuracy: 1.0000 - val_loss: 0.1607 - val_binary_accuracy: 0.9859\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.7213e-04 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 43). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 15s 4s/step - loss: 3.7213e-04 - binary_accuracy: 1.0000 - val_loss: 0.1600 - val_binary_accuracy: 0.9859\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0037 - binary_accuracy: 1.0000 - val_loss: 0.1763 - val_binary_accuracy: 0.9718\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.0392e-04 - binary_accuracy: 1.0000 - val_loss: 0.1876 - val_binary_accuracy: 0.9718\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.8514e-04 - binary_accuracy: 1.0000 - val_loss: 0.1975 - val_binary_accuracy: 0.9718\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.4922e-05 - binary_accuracy: 1.0000 - val_loss: 0.2059 - val_binary_accuracy: 0.9718\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.0433e-04 - binary_accuracy: 1.0000 - val_loss: 0.2119 - val_binary_accuracy: 0.9577\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.0105e-05 - binary_accuracy: 1.0000 - val_loss: 0.2163 - val_binary_accuracy: 0.9577\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.4551e-05 - binary_accuracy: 1.0000 - val_loss: 0.2195 - val_binary_accuracy: 0.9577\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.8412e-05 - binary_accuracy: 1.0000 - val_loss: 0.2218 - val_binary_accuracy: 0.9577\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.2148e-04 - binary_accuracy: 1.0000 - val_loss: 0.2257 - val_binary_accuracy: 0.9577\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.8465e-05 - binary_accuracy: 1.0000 - val_loss: 0.2305 - val_binary_accuracy: 0.9577\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.8749e-05 - binary_accuracy: 1.0000 - val_loss: 0.2340 - val_binary_accuracy: 0.9577\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.9143e-05 - binary_accuracy: 1.0000 - val_loss: 0.2364 - val_binary_accuracy: 0.9577\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.3131e-05 - binary_accuracy: 1.0000 - val_loss: 0.2378 - val_binary_accuracy: 0.9577\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.7015e-05 - binary_accuracy: 1.0000 - val_loss: 0.2386 - val_binary_accuracy: 0.9577\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.6142e-05 - binary_accuracy: 1.0000 - val_loss: 0.2394 - val_binary_accuracy: 0.9577\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.1017e-05 - binary_accuracy: 1.0000 - val_loss: 0.2400 - val_binary_accuracy: 0.9577\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.0578e-04 - binary_accuracy: 1.0000 - val_loss: 0.2414 - val_binary_accuracy: 0.9577\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.0408e-05 - binary_accuracy: 1.0000 - val_loss: 0.2422 - val_binary_accuracy: 0.9577\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.5368e-05 - binary_accuracy: 1.0000 - val_loss: 0.2431 - val_binary_accuracy: 0.9577\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.2482e-05 - binary_accuracy: 1.0000 - val_loss: 0.2441 - val_binary_accuracy: 0.9577\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.3050e-05 - binary_accuracy: 1.0000 - val_loss: 0.2452 - val_binary_accuracy: 0.9577\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.9246e-05 - binary_accuracy: 1.0000 - val_loss: 0.2463 - val_binary_accuracy: 0.9577\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.6031e-06 - binary_accuracy: 1.0000 - val_loss: 0.2475 - val_binary_accuracy: 0.9577\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.5710e-05 - binary_accuracy: 1.0000 - val_loss: 0.2487 - val_binary_accuracy: 0.9577\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.9190e-06 - binary_accuracy: 1.0000 - val_loss: 0.2498 - val_binary_accuracy: 0.9577\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.9430e-05 - binary_accuracy: 1.0000 - val_loss: 0.2508 - val_binary_accuracy: 0.9577\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.0155e-06 - binary_accuracy: 1.0000 - val_loss: 0.2515 - val_binary_accuracy: 0.9577\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0016 - binary_accuracy: 0.9984 - val_loss: 0.2475 - val_binary_accuracy: 0.9577\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0032 - binary_accuracy: 0.9984 - val_loss: 0.2576 - val_binary_accuracy: 0.9577\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.6927e-04 - binary_accuracy: 1.0000 - val_loss: 0.3304 - val_binary_accuracy: 0.9577\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.4390e-04 - binary_accuracy: 1.0000 - val_loss: 0.3280 - val_binary_accuracy: 0.9577\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0014 - binary_accuracy: 0.9984 - val_loss: 0.3164 - val_binary_accuracy: 0.9437\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.7240e-04 - binary_accuracy: 1.0000 - val_loss: 0.3964 - val_binary_accuracy: 0.9296\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0036 - binary_accuracy: 0.9984 - val_loss: 0.3262 - val_binary_accuracy: 0.9437\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0212 - binary_accuracy: 0.9937 - val_loss: 0.3574 - val_binary_accuracy: 0.9577\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0258 - binary_accuracy: 0.9922 - val_loss: 0.1971 - val_binary_accuracy: 0.9718\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0493 - binary_accuracy: 0.9796 - val_loss: 0.1912 - val_binary_accuracy: 0.9577\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0294 - binary_accuracy: 0.9922 - val_loss: 0.1941 - val_binary_accuracy: 0.9718\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0351 - binary_accuracy: 0.9843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 43). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tcg_ResNet40.model_-f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 15s 4s/step - loss: 0.0351 - binary_accuracy: 0.9843 - val_loss: 0.1580 - val_binary_accuracy: 0.9577\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0087 - binary_accuracy: 0.9953 - val_loss: 0.1957 - val_binary_accuracy: 0.9155\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0060 - binary_accuracy: 0.9984 - val_loss: 0.1593 - val_binary_accuracy: 0.9577\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 0.1798 - val_binary_accuracy: 0.9718\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 0.2168 - val_binary_accuracy: 0.9718\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.4559e-04 - binary_accuracy: 1.0000 - val_loss: 0.2469 - val_binary_accuracy: 0.9437\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.3811e-04 - binary_accuracy: 1.0000 - val_loss: 0.2675 - val_binary_accuracy: 0.9437\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.2342e-04 - binary_accuracy: 1.0000 - val_loss: 0.2756 - val_binary_accuracy: 0.9577\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.7313e-04 - binary_accuracy: 1.0000 - val_loss: 0.2810 - val_binary_accuracy: 0.9577\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.3535e-05 - binary_accuracy: 1.0000 - val_loss: 0.2860 - val_binary_accuracy: 0.9577\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.2276e-05 - binary_accuracy: 1.0000 - val_loss: 0.2882 - val_binary_accuracy: 0.9577\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.1404e-05 - binary_accuracy: 1.0000 - val_loss: 0.2892 - val_binary_accuracy: 0.9577\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.5587e-05 - binary_accuracy: 1.0000 - val_loss: 0.2899 - val_binary_accuracy: 0.9577\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.2439e-05 - binary_accuracy: 1.0000 - val_loss: 0.2901 - val_binary_accuracy: 0.9577\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.8989e-05 - binary_accuracy: 1.0000 - val_loss: 0.2908 - val_binary_accuracy: 0.9577\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.2487e-05 - binary_accuracy: 1.0000 - val_loss: 0.2909 - val_binary_accuracy: 0.9577\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.6238e-05 - binary_accuracy: 1.0000 - val_loss: 0.2908 - val_binary_accuracy: 0.9577\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.2093e-05 - binary_accuracy: 1.0000 - val_loss: 0.2906 - val_binary_accuracy: 0.9577\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.7146e-05 - binary_accuracy: 1.0000 - val_loss: 0.2907 - val_binary_accuracy: 0.9577\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.9426e-05 - binary_accuracy: 1.0000 - val_loss: 0.2907 - val_binary_accuracy: 0.9577\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.4230e-05 - binary_accuracy: 1.0000 - val_loss: 0.2907 - val_binary_accuracy: 0.9577\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.2586e-05 - binary_accuracy: 1.0000 - val_loss: 0.2906 - val_binary_accuracy: 0.9577\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.7217e-05 - binary_accuracy: 1.0000 - val_loss: 0.2907 - val_binary_accuracy: 0.9577\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.5871e-05 - binary_accuracy: 1.0000 - val_loss: 0.2913 - val_binary_accuracy: 0.9577\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.0028e-06 - binary_accuracy: 1.0000 - val_loss: 0.2917 - val_binary_accuracy: 0.9577\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.2082e-05 - binary_accuracy: 1.0000 - val_loss: 0.2919 - val_binary_accuracy: 0.9577\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.8069e-05 - binary_accuracy: 1.0000 - val_loss: 0.2922 - val_binary_accuracy: 0.9577\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.3621e-05 - binary_accuracy: 1.0000 - val_loss: 0.2925 - val_binary_accuracy: 0.9577\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.1075e-05 - binary_accuracy: 1.0000 - val_loss: 0.2932 - val_binary_accuracy: 0.9577\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.1947e-06 - binary_accuracy: 1.0000 - val_loss: 0.2936 - val_binary_accuracy: 0.9577\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.2112e-06 - binary_accuracy: 1.0000 - val_loss: 0.2939 - val_binary_accuracy: 0.9577\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.8278e-05 - binary_accuracy: 1.0000 - val_loss: 0.2955 - val_binary_accuracy: 0.9577\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.6062e-05 - binary_accuracy: 1.0000 - val_loss: 0.2969 - val_binary_accuracy: 0.9577\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.4522e-05 - binary_accuracy: 1.0000 - val_loss: 0.2980 - val_binary_accuracy: 0.9577\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.9606e-06 - binary_accuracy: 1.0000 - val_loss: 0.2989 - val_binary_accuracy: 0.9577\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.3059e-06 - binary_accuracy: 1.0000 - val_loss: 0.2994 - val_binary_accuracy: 0.9577\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.3417e-06 - binary_accuracy: 1.0000 - val_loss: 0.2998 - val_binary_accuracy: 0.9577\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.6864e-06 - binary_accuracy: 1.0000 - val_loss: 0.3001 - val_binary_accuracy: 0.9577\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.3325e-06 - binary_accuracy: 1.0000 - val_loss: 0.3003 - val_binary_accuracy: 0.9577\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.4955e-05 - binary_accuracy: 1.0000 - val_loss: 0.3006 - val_binary_accuracy: 0.9577\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.9310e-05 - binary_accuracy: 1.0000 - val_loss: 0.3009 - val_binary_accuracy: 0.9577\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.7529e-05 - binary_accuracy: 1.0000 - val_loss: 0.3011 - val_binary_accuracy: 0.9577\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.5698e-05 - binary_accuracy: 1.0000 - val_loss: 0.3014 - val_binary_accuracy: 0.9577\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.1186e-05 - binary_accuracy: 1.0000 - val_loss: 0.3017 - val_binary_accuracy: 0.9577\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.8399e-05 - binary_accuracy: 1.0000 - val_loss: 0.3021 - val_binary_accuracy: 0.9577\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.8500e-05 - binary_accuracy: 1.0000 - val_loss: 0.3026 - val_binary_accuracy: 0.9577\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.1538e-05 - binary_accuracy: 1.0000 - val_loss: 0.3030 - val_binary_accuracy: 0.9577\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.1206e-05 - binary_accuracy: 1.0000 - val_loss: 0.3035 - val_binary_accuracy: 0.9577\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.1143e-05 - binary_accuracy: 1.0000 - val_loss: 0.3040 - val_binary_accuracy: 0.9577\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.4645e-06 - binary_accuracy: 1.0000 - val_loss: 0.3044 - val_binary_accuracy: 0.9577\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.7539e-04 - binary_accuracy: 1.0000 - val_loss: 0.3086 - val_binary_accuracy: 0.9577\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.1312e-06 - binary_accuracy: 1.0000 - val_loss: 0.3185 - val_binary_accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# main function\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    n = len(sys.argv)\n",
    "    print(\"Total arguments input are:\", n)\n",
    "    print(\"Name of Python script:\", sys.argv[0])\n",
    "    if n < 2:\n",
    "       print(\"Need a forecast lead time to process...Stop\")\n",
    "       print(\"+ Example: tcg_ResNet_p2.py 00\")\n",
    "       exit()\n",
    "    leadtime = str(sys.argv[1])\n",
    "    print(\"Forecast lead time to run is: \",leadtime)\n",
    "    #sys.exit()\n",
    "    #\n",
    "    # read in data output from Part 1 and normalize it\n",
    "    #\n",
    "    pickle_in = open(\"tcg_ResNet_X.pickle\",\"rb\")\n",
    "    X = pickle.load(pickle_in)\n",
    "    pickle_in = open(\"tcg_ResNet_y.pickle\",\"rb\")\n",
    "    y = pickle.load(pickle_in)\n",
    "    Y = np.array(y)\n",
    "    number_channels=X.shape[3]\n",
    "    print('Input shape of the X features data: ',X.shape)\n",
    "    print('Input shape of the y label data: ',Y.shape)\n",
    "    print('Number of input channel extracted from X is: ',number_channels)\n",
    "\n",
    "    x_train,y_train = tcg_utils.normalize_channels(X,Y)\n",
    "    print (\"number of input examples = \" + str(X.shape[0]))\n",
    "    print (\"X shape: \" + str(X.shape))\n",
    "    print (\"Y shape: \" + str(Y.shape))\n",
    "    #\n",
    "    # define the model architecture\n",
    "    #\n",
    "    DENSE_LAYER = [0, 1, 2]\n",
    "    LAYER_SIZES = [32]\n",
    "    CONV_LAYERS = [3, 5]\n",
    "    resnets = ['ResNet20', 'ResNet22', 'ResNet40']\n",
    "    histories = main(resnet_models=resnets,X=x_train,y=y_train,lead_time=leadtime)\n",
    "    with open('./tcg_histories_resnet.pickle', 'wb') as out:\n",
    "        pickle.dump(histories,out)\n",
    "\n",
    "    check_visualization = \"yes\"\n",
    "    if check_visualization== \"yes\":\n",
    "        view_history(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a24cc6-0eef-4d1d-84da-114d5430ea38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
